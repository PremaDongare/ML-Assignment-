# -*- coding: utf-8 -*-
"""Assignment4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DUIGKUKfGrN5Gi6yRWUaVqOR4G--xaxK

#Perform the following operations using R/Python on the data sets:
#a) Compute and display summary statistics for each feature available in the dataset. (e.g. minimum value, maximum value, mean, range, standard deviation, variance and percentiles
#b) Data Visualization-Create a histogram for each feature in the dataset to illustrate the feature distributions.
#c) Data cleaning, Data integration, Data transformation, Data model building (e.g. Classification)
"""

import pandas as pd
import numpy as np
import seaborn as sn
import matplotlib.pyplot as plt

df=pd.read_csv("Customer_Behaviour.csv")
df.head()

"""a) **Compute and display summary statistics for each feature available in the dataset. (e.g. minimum value, maximum value, mean, range, standard deviation, variance and percentiles** **bold text** **bold text**

"""

print(df.info())

print(df.describe())

sum_static= df.describe().T
sum_static["range"]= sum_static["max"]-sum_static["min"]
print(sum_static)

"""# **Data Visualization-Create a histogram for each feature in the dataset to illustrate the feature distributions.**"""

sn.set_style("whitegrid")
numerical_feature=["Age","EstimatedSalary"]

fig,axes=plt.subplots(1,2,figsize=(12,5))

for i, col in enumerate(numerical_feature):
    sn.histplot(data=df,x=col,ax=axes[i])
plt.tight_layout()
plt.show()

# Plot histogram to compare Male vs Female distributions
plt.figure(figsize=(8, 5))
sn.histplot(df, x="Age", hue="Gender", bins=20, kde=True, palette={"Male": "blue", "Female": "pink"}, alpha=0.6)

plt.title("Age Distribution by Gender")
plt.xlabel("Age")
plt.ylabel("Count")
plt.legend(title="Gender")
plt.show()

"""**Data cleaning, Data integration, Data transformation, Data model building (e.g. Classification)**

"""

from sklearn.preprocessing import LabelEncoder, StandardScaler
df_cleaned= df.drop(columns=["User ID"]) # droped because not needed
# label encoder for female  and mail
label_encoder = LabelEncoder()
df_cleaned["Gender"] = label_encoder.fit_transform(df_cleaned["Gender"]) #Male=1, Female=0
# standardiz numerical feature
scaler = StandardScaler()
df_cleaned[["Age", "EstimatedSalary"]] = scaler.fit_transform(df_cleaned[["Age", "EstimatedSalary"]])

print(df_cleaned.head())

"""**Split Data into Training and Testing Sets**"""

from sklearn.model_selection import train_test_split

X=df_cleaned.drop(columns=["Purchased"])
Y=df_cleaned["Purchased"]

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)
print(f"Training Set: {X_train.shape}, Test Set: {X_test.shape}")

"""**Train a Classification Model (Logistic Regression)**"""

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()
model.fit(X_train,Y_train)

"""Predict for a New Customer
If a 30-year-old female with a salary of 60,000 wants to be predicted:
"""

# Example new customer (Gender: Female, Age: 30, Salary: 60000)
new_customer = pd.DataFrame([[0, 30, 60000]], columns=["Gender", "Age", "EstimatedSalary"])

# Standardize Age and Salary (using the same scaler from training)
new_customer[["Age", "EstimatedSalary"]] = scaler.transform(new_customer[["Age", "EstimatedSalary"]])

# Predict purchase decision
purchase_prediction = model.predict(new_customer)

# Show result
print("Prediction (1=Will Purchase, 0=Will Not Purchase):", purchase_prediction[0])

